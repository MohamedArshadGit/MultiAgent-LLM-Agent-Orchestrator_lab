{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdebc876",
   "metadata": {},
   "source": [
    "Chatbot with tool capabilities from arxiv ,wikipedia Search,Internet Search like Google\n",
    " and some custom tool functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d016848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ccec856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed Arshad\\Projects\\agents\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dcb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arxiv \n",
    "arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper(doc_content_chars_max=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44acf799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2021-05-06\\nTitle: Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet\\nAuthors: Luke Melas-Kyriazi\\nSummary: The strong performance of vision transformers on image classification and other vision tasks is often attributed to the design of their multi-head attention layers. However, the extent to which attention is responsible for this strong performance remains unclear. In this short report, we ask: is the attention layer even necessary? Specifically, we replace the attention layer in a vision transformer with a feed-forward layer applied over the patch dimension. The resulting architecture is simply a series of feed-forward layers applied over the patch and feature dimensions in an alternating fashion. In experiments on ImageNet, this architecture performs surprisingly well: a ViT/DeiT-base-sized model obtains 74.9\\\\% top-1 accuracy, compared to 77.9\\\\% and 79.9\\\\% for ViT and DeiT respectively. These results indicate that aspects of vision transformers other than attention, such as the patch embedding, may be more responsible for their strong performance than previously thought. We hope these results prompt the community to spend more time trying to understand why our current models are as effective as they are.\\n\\nPublished: 2025-12-03\\nTitle: \"All You Need\" is Not All You Need for a Paper Title: On the Origins of a Scientific Meme\\nAuthors: Anton Alyakin\\nSummary: The 2017 paper \\'\\'Attention Is All You Need\\'\\' introduced the Transformer architecture-and inadvertently spawned one of machine learning\\'s most persistent naming conventions. We analyze 717 arXiv preprints containing \\'\\'All You Need\\'\\' in their titles (2009-2025), finding exponential growth ($R^2$ > 0.994) following the original paper, with 200 titles in 2025 alone. Among papers following the canonical \\'\\'X [Is] All You Need\\'\\' structure, \\'\\'Attention\\'\\' remains the most frequently claimed necessity (28 occurrences). Situating this phenomenon within memetic theory, we argue the pattern\\'s success reflects competitive pressures in scientific communication that increasingly favor memorability over precision. Whether this trend represents harmless academic whimsy or symptomatic sensationalism, we leave-with appropriate self-awareness-to the reader.\\n\\nPublished: 2018-06-28\\nTitle: Quit When You Can: Efficient Evaluation of Ensembles with Ordering Optimization\\nAuthors: Serena Wang, Maya Gupta, Seungil You\\nSummary: Given a classifier ensemble and a set of examples to be classified, many examples may be confidently and accurately classified after only a subset of the base models in the ensemble are evaluated. This can reduce both mean latency and CPU while maintaining the high accuracy of the original ensemble. To achieve such gains, we propose jointly optimizing a fixed evaluation order of the base models and early-stopping thresholds. Our proposed objective is a combinatorial optimization problem, but we provide a greedy algorithm that achieves a 4-approximation of the optimal solution for certain cases. For those cases, this is also the best achievable polynomial time approximation bound unless $P = NP$. Experiments on benchmark and real-world problems show that the proposed Quit When You Can (QWYC) algorithm can speed-up average evaluation time by $2$x--$4$x, and is around $1.5$x faster than prior work. QWYC\\'s joint optimization of ordering and thresholds also performed better in experiments than various fixed orderings, including gradient boosted trees\\' ordering.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke('Attention is all you need')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876b773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia\n",
    "wikipedia =WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=2,doc_content_chars_max=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7daf438e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.run('Langgraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55190c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['GROQ_API_KEY'] =os.getenv('GROQ_API_KEY')\n",
    "os.environ['TAVILY_API_KEY'] =os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a164d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed Arshad\\Projects\\agents\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"output_schema\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mohamed Arshad\\Projects\\agents\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:198: UserWarning: Field name \"stream\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tavily Search Tool-> Internet Search tool\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    # include_answer=False,\n",
    "    # include_raw_content=False,\n",
    "    # include_images=False,\n",
    "    # include_image_descriptions=False,\n",
    "    # search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44323cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'recent ai news on 12 jan 2026',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.theguardian.com/media/2026/jan/12/publishers-fear-ai-search-summaries-and-chatbots-mean-end-of-traffic-era',\n",
       "   'title': \"Publishers fear AI search summaries and chatbots mean 'end of ...\",\n",
       "   'content': 'Mon 12 Jan 2026 01.00 EST. Share. Media companies expect web traffic to their sites from online searches to plummet over the next three years, as AI',\n",
       "   'score': 0.83710164,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.fool.com/investing/2026/01/12/a-once-in-a-decade-investment-opportunity-the-best/',\n",
       "   'title': 'The Best Artificial Intelligence (AI) Stock to Buy in 2026',\n",
       "   'content': 'A Once-in-a-Decade Investment Opportunity: The Best Artificial Intelligence (AI) Stock to Buy in 2026. By Adam Spatacco ‚Äì Jan 12, 2026 at 7:45AM',\n",
       "   'score': 0.8058924,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.clickondetroit.com/news/local/2026/01/12/shadow-ai-nearly-half-of-employees-say-theyve-uploaded-sensitive-data-into-ai-chats/',\n",
       "   'title': \"Shadow AI: Nearly half of employees say they've uploaded sensitive ...\",\n",
       "   'content': \"Shadow AI: Nearly half of employees say they've uploaded sensitive data into AI chats. Personal devices complicate AI policy enforcement.\",\n",
       "   'score': 0.80405265,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.cnn.com/2026/01/12/business/video/tokyo-fii-priority-asia-2025-mpa-hnk-spc',\n",
       "   'title': 'The future of AI, innovation and investment in Asia | CNN Business',\n",
       "   'content': '... January 12, 2026. Link Copied! ... News Network. A Warner Bros. Discovery Company. All Rights Reserved. CNN Sans ‚Ñ¢ & ¬© 2016 Cable News',\n",
       "   'score': 0.79215926,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://reliefweb.int/report/world/has-humanitarian-ai-paradox-started-shift-dfs-and-hla-launch-follow-pulse-survey-measure-change-2026',\n",
       "   'title': 'Has the Humanitarian AI Paradox Started to Shift? DFS and HLA ...',\n",
       "   'content': 'DFS and HLA Launch Follow-Up Pulse Survey to Measure Change in 2026. Format: News and Press Release; Source. DFS. Posted: 12 Jan 2026',\n",
       "   'score': 0.7763013,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.88,\n",
       " 'request_id': 'dde5485a-2fd9-4a6e-9d6f-c9de7a87b3a0'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"recent ai news on 12 jan 2026\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce77a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tools\n",
    "tools =[arxiv,wikipedia,tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b049d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat model\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm =ChatGroq(model = 'llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83da64df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 37, 'total_tokens': 60, 'completion_time': 0.072355469, 'completion_tokens_details': None, 'prompt_time': 0.002775943, 'prompt_tokens_details': None, 'queue_time': 0.089765765, 'total_time': 0.075131412}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb2b9-1821-7e21-b855-83f6b15f8a15-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 37, 'output_tokens': 23, 'total_tokens': 60})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('hey there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d5ec59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is mandate\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28de9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '9k5fjg336', 'function': {'arguments': '{\"query\":\"Attention is All You Need\"}', 'name': 'arxiv'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1959, 'total_tokens': 1978, 'completion_time': 0.028640443, 'completion_tokens_details': None, 'prompt_time': 0.176879993, 'prompt_tokens_details': None, 'queue_time': 0.124969747, 'total_time': 0.205520436}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb2b9-1abf-7393-bf83-932a50d4bcd2-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Attention is All You Need'}, 'id': '9k5fjg336', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1959, 'output_tokens': 19, 'total_tokens': 1978})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether llm is calling the right tool when needed\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "\n",
    "llm_with_tools.invoke([HumanMessage(content=\"what is attention is all you need ?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d04c9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from IPython.display import Image,display\n",
    "from langgraph.graph.message import AnyMessage,add_messages\n",
    "from typing import TypedDict,Annotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97b926b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining State Schema \n",
    "# Define the State of the Graph\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd218a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b9da5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize state Graph\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('tool_calling_llm',tool_calling_llm)\n",
    "graph.add_node('tools',ToolNode(tools))\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START,'tool_calling_llm')\n",
    "graph.add_conditional_edges('tool_calling_llm',tools_condition)\n",
    "graph.add_edge('tools','tool_calling_llm')\n",
    "\n",
    "graph_builder = graph.compile()\n",
    "\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f372cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "system_prompt = SystemMessage(\n",
    "    content=\"\"\"\n",
    "You are a research assistant.\n",
    "- Use Arxiv for original papers\n",
    "- Use Tavily for recent information\n",
    "- Use multiple tools if needed\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea65fe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain_core.messages import HumanMessage\\n\\ndef chat(user_input,history):\\n    result =graph_builder.invoke({\"messages\":[system_prompt,HumanMessage(content=user_input)]})\\n    print(result)\\n    return result[\\'messages\\'][-1].content\\n\\ngr.ChatInterface(chat,type=\"messages\").launch()'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\"\"\"from langchain_core.messages import HumanMessage\n",
    "\n",
    "def chat(user_input,history):\n",
    "    result =graph_builder.invoke({\"messages\":[system_prompt,HumanMessage(content=user_input)]})\n",
    "    print(result)\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "gr.ChatInterface(chat,type=\"messages\").launch()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a42057ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "def debug_event_printer(event):\n",
    "    for node, state in event.items():\n",
    "        print(f\"\\nüîπ NODE: {node}\")\n",
    "\n",
    "        messages = state.get(\"messages\", [])\n",
    "        last = messages[-1] if messages else None\n",
    "\n",
    "        if isinstance(last, AIMessage):\n",
    "            # LLM step\n",
    "            print(\"ü§ñ LLM OUTPUT:\")\n",
    "            print(last.content)\n",
    "\n",
    "            if last.tool_calls:\n",
    "                print(\"üõ† TOOL CALLS:\")\n",
    "                for tc in last.tool_calls:\n",
    "                    print(f\"  ‚Üí Tool: {tc['name']}\")\n",
    "                    print(f\"    Args: {tc['args']}\")\n",
    "\n",
    "        elif isinstance(last, ToolMessage):\n",
    "            print(\"üîß TOOL OUTPUT:\")\n",
    "            print(last.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d5f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def chat(user_input, history):\n",
    "    inputs = {\n",
    "        \"messages\": [system_prompt, HumanMessage(content=user_input)]\n",
    "    }\n",
    "\n",
    "    print(\"\\n================ NEW QUERY ================\\n\")\n",
    "\n",
    "    last_messages = None\n",
    "\n",
    "    for event in graph_builder.stream(inputs):\n",
    "        debug_event_printer(event)\n",
    "\n",
    "        # event = {\"node_name\": {\"messages\": [...]}}\n",
    "        node_state = list(event.values())[0]\n",
    "        if \"messages\" in node_state:\n",
    "            last_messages = node_state[\"messages\"]\n",
    "\n",
    "    print(\"\\n=============== FINAL ANSWER ===============\\n\")\n",
    "\n",
    "    return last_messages[-1].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: arxiv\n",
      "    Args: {'query': 'BERT paper abstract and main idea'}\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'query': 'BERT paper abstract and main idea', 'start_date': '2020-11-01', 'topic': 'news'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"BERT paper abstract and main idea\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.facebook.com/groups/nichesitemasteryclub/posts/1320819518542841/\", \"title\": \"What are the key advantages of the bert model in NLP?\", \"content\": \"The Core Idea of the Paper The paper's central idea is that attention mechanisms are sufficient for handling sequence-to-sequence tasks, such as machine\", \"score\": 0.9990601, \"raw_content\": null}, {\"url\": \"https://dl.acm.org/doi/10.1145/3746709.3746721\", \"title\": \"Research and Implementation of Text Classification Based ...\", \"content\": \"Abstract. This paper focuses on automatic text classification using the BERT model. [1] It optimizes word vectors in the embedding layer, extracts context\", \"score\": 0.99837697, \"raw_content\": null}, {\"url\": \"https://www.sciencedirect.com/science/article/pii/S2667096825000357\", \"title\": \"ABERT: Adapting BERT model for efficient detection of ...\", \"content\": \"by J Alghamdi ¬∑ 2025 ¬∑ Cited by 4 ‚Äî In this study, we propose a novel approach, Adapt-BERT (ABERT), for the detection of both human and artificial intelligence (AI)-generated fake news.\", \"score\": 0.99818975, \"raw_content\": null}, {\"url\": \"https://aclanthology.org/N19-1423/\", \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers for ...\", \"content\": \"by J Devlin ¬∑ 2019 ¬∑ Cited by 153142 ‚Äî Abstract. We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.\", \"score\": 0.99701905, \"raw_content\": null}, {\"url\": \"https://gmihaila.medium.com/%EF%B8%8F-bert-inner-workings-1c3054cd1591\", \"title\": \"Bert Inner Workings. Let's look at how an input flows‚Ä¶\", \"content\": \"Main idea: I created this notebook to better understand the inner workings of Bert. I followed a lot of tutorials to try to understand the architecture, but\", \"score\": 0.99549675, \"raw_content\": null}], \"response_time\": 0.81, \"request_id\": \"52d117a9-7dfc-4f3e-ba4c-60e8f6a0480e\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "The BERT paper abstract and main idea are as follows:\n",
      "\n",
      "Abstract: The paper introduces a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT is a pre-trained language model that uses a multi-layer bidirectional transformer encoder to generate contextualized representations of words in a sentence. The model is trained on a large corpus of text data and can be fine-tuned for specific tasks such as question answering, sentiment analysis, and language translation.\n",
      "\n",
      "Main idea: The main idea of the BERT paper is to show that attention mechanisms are sufficient for handling sequence-to-sequence tasks, such as machine translation and text classification. The paper proposes a new language representation model called BERT, which uses a multi-layer bidirectional transformer encoder to generate contextualized representations of words in a sentence. The model is pre-trained on a large corpus of text data and can be fine-tuned for specific tasks. The paper also presents several experiments to demonstrate the effectiveness of BERT on various natural language processing tasks.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: arxiv\n",
      "    Args: {'query': 'Transformer paper authors'}\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'end_date': '2017-10-31', 'query': 'Transformer paper authors', 'start_date': '2017-10-01', 'topic': 'news'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"Transformer paper authors\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://github.com/daniilidis-group/polar-transformer-networks\", \"title\": \"daniilidis-group/polar-transformer-networks\", \"content\": \"Demo source code for the paper \\\"Esteves, C., Allen-Blanchette, C., Zhou, X. and Daniilidis, K, \\\"Polar Transformer Networks\\\", ICLR 2018.\", \"score\": 0.9433476, \"raw_content\": null}, {\"url\": \"https://passive-components.eu/flyback-transformer-modelling/\", \"title\": \"Flyback Transformer Modelling\", \"content\": \"Developed software is free of charge. Contact authors to receive the software. Title: Flyback Transformer Modelling Author(s): Farzin Asadi*1, Nurettin Abut*2\", \"score\": 0.8840393, \"raw_content\": null}, {\"url\": \"https://www.mdpi.com/2072-4292/15/10/2696\", \"title\": \"Spectral-Swin Transformer with Spatial Feature Extraction ...\", \"content\": \"by Y Peng ¬∑ 2023 ¬∑ Cited by 26 ‚Äî All the authors made significant contributions to the work. Y.P., J.R. and J.W. designed the research, analyzed the results, and accomplished the validation\", \"score\": 0.258326, \"raw_content\": null}, {\"url\": \"https://ieeexplore.ieee.org/document/6070213/\", \"title\": \"Applications of probability model to analyze the effects ...\", \"content\": \"by JM Sexauer ¬∑ 2011 ¬∑ Cited by 119 ‚Äî The authors use a binomial probability model to calculate the probability that a specific distribution transformer will experience excessive loading.\", \"score\": 0.10302443, \"raw_content\": null}, {\"url\": \"https://www.semanticscholar.org/paper/A-half-turn-winding-for-compact%2C-high-current%2C-Iyer-Cai/000fe9de35ad3d3d13ddacca98fc708fe812f61f/figure/4\", \"title\": \"Figure 4 from A half-turn winding for compact, high-current, ...\", \"content\": \"A half-turn winding for compact, high-current, high-turns-ratio, low-leakage-inductance transformer ¬∑ K. Iyer, M. Cai, +2 authors. N. Mohan ¬∑ Published in\", \"score\": 0.090092994, \"raw_content\": null}], \"response_time\": 0.93, \"request_id\": \"223750ef-82f7-471c-96a6-f28766dca2fd\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "The authors of the Transformer paper are Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, and Illia Polosukhin.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'query': 'Groq', 'start_date': '2024-01-01', 'topic': 'news'}\n",
      "  ‚Üí Tool: wikipedia\n",
      "    Args: {'query': 'Groq'}\n",
      "  ‚Üí Tool: arxiv\n",
      "    Args: {'query': 'Groq'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "Published: 2025-05-24\n",
      "Title: GRoQ-LoCO: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets\n",
      "Authors: Narayanan PP, Sarvesh Prasanth Venkatesan, Srinivas Kantha Reddy, Shishir Kolathaya\n",
      "Summary: Recent advancements in large-scale offline training have demonstrated the potential of generalist policy learning for complex robotic tasks. However, applying these principles to legged locomotion remains a challenge due to continuous dynamics and the need for real-time adaptation across diverse terrains and robot morphologies. In this work, we propose GRoQ-LoCO, a scalable, attention-based framework that learns a single generalist locomotion policy across multiple quadruped robots and terrains, relying solely on offline datasets. Our approach leverages expert demonstrations from two distinct locomotion behaviors - stair traversal (non-periodic gaits) and flat terrain traversal (periodic gaits) - collected across multiple quadruped robots, to train a generalist model that enables behavior fusion. Crucially, our framework operates solely on proprioceptive data from all robots without incorporating any robot-specific encodings. The policy is directly deployable on an Intel i7 nuc, producing low-latency control outputs without any test-time optimization. Our extensive experiments demonstrate zero-shot transfer across highly diverse quadruped robots and terrains, including hardware deployment on the Unitree Go1, a commercially available 12kg robot. Notably, we evaluate challenging cross-robot training setups where different locomotion skills are unevenly distributed across robots, yet observe successful transfer of both flat walking and stair traversal behaviors to all robots at test time. We also show preliminary walking on Stoch 5, a 70kg quadruped, on flat and outdoor terrains without requiring any fine tuning. These results demonstrate the potential of offline, data-driven learning to generalize locomotion across diverse quadruped morphologies and behaviors.\n",
      "\n",
      "Published: 2025-07-14\n",
      "Title: Abusive text transformation using LLMs\n",
      "Authors: Rohitash Chandra, Jiyong Choi\n",
      "Summary: Although Large Language Models (LLMs) have demonstrated significant advancements in natural language processing tasks, their effectiveness in the classification and transformation of abusive text into non-abusive versions remains an area for exploration. In this study, we aim to use LLMs to transform abusive text (tweets and reviews) featuring hate speech and swear words into non-abusive text, while retaining the intent of the text. We evaluate the performance of two state-of-the-art LLMs, such as Gemini, GPT-4o, DeekSeek and Groq, on their ability to identify abusive text. We them to transform and obtain a text that is clean from abusive and inappropriate content but maintains a similar level of sentiment and semantics, i.e. the transformed text needs to maintain its message. Afterwards, we evaluate the raw and transformed datasets with sentiment analysis and semantic analysis. Our results show Groq provides vastly different results when compared with other LLMs. We have identified similarities between GPT-4o and DeepSeek-V3.\n",
      "\n",
      "Published: 2024-10-22\n",
      "Title: Personalized Recommendation Systems using Multimodal, Autonomous, Multi Agent Systems\n",
      "Authors: Param Thakkar, Anushka Yadav\n",
      "Summary: This paper describes a highly developed personalised recommendation system using multimodal, autonomous, multi-agent systems. The system focuses on the incorporation of futuristic AI tech and LLMs like Gemini-1.5- pro and LLaMA-70B to improve customer service experiences especially within e-commerce. Our approach uses multi agent, multimodal systems to provide best possible recommendations to its users. The system is made up of three agents as a whole. The first agent recommends products appropriate for answering the given question, while the second asks follow-up questions based on images that belong to these recommended products and is followed up with an autonomous search by the third agent. It also features a real-time data fetch, user preferences-based recommendations and is adaptive learning. During complicated queries the application processes with Symphony, and uses the Groq API to answer quickly with low response times. It uses a multimodal way to utilize text and images comprehensively, so as to optimize product recommendation and customer interaction.\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "The research assistant was able to find the following information about Groq:\n",
      "\n",
      "Groq is an American artificial intelligence (AI) company that builds an AI accelerator application-specific integrated circuit (ASIC). The architecture was originally introduced as a Tensor Streaming Processor (TSP) but was later rebranded as a Language Processing Unit (LPU) following the widespread adoption of large language models after the breakthrough of ChatGPT. The company also develops related computer hardware and software to accelerate AI inference performance.\n",
      "\n",
      "Groq has received significant funding, including a $1.5 billion commitment from the Kingdom of Saudi Arabia in 2025. The company has also secured a licensing deal with Nvidia, which has been seen as a strategic move to maintain dominance in the AI market.\n",
      "\n",
      "Groq's LPU architecture is designed for inference and offers exceptional speed and affordability at scale. The company's platform is used by over 2.5 million developers and has been adopted by several high-profile customers, including the McLaren F1 Team.\n",
      "\n",
      "Groq has also developed a cloud-based platform called GroqCloud, which provides a suite of tools and services for building, deploying, and managing AI models. The company's technology is also used in various industries, including healthcare, finance, and retail.\n",
      "\n",
      "The research assistant was able to find several papers related to Groq, including a paper on GRoQ-LoCO, a scalable, attention-based framework that learns a single generalist locomotion policy across multiple quadruped robots and terrains, relying solely on offline datasets. Another paper discusses the use of LLMs to transform abusive text into non-abusive versions, with Groq providing vastly different results when compared with other LLMs. A third paper describes a personalized recommendation system using multimodal, autonomous, multi-agent systems, which incorporates futuristic AI tech and LLMs like Gemini-1.5-pro and LLaMA-70B to improve customer service experiences.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'query': 'OpenAI recent news', 'search_depth': 'advanced', 'start_date': '2024-01-01', 'topic': 'news'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"OpenAI recent news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.theverge.com/openai\", \"title\": \"OpenAI | The Verge\", \"content\": \"According to a report from Wired, sources at OpenAI say the company ‚Äúhas become more reluctant to release work that highlights the economic downsides of AI.‚Äù At least two employees have reportedly left as a result of research restrictions, including former researcher Tom Cunningham:\\n\\n‚ÄúIn a parting message shared internally, Cunningham wrote that the team faced a growing tension between conducting rigorous analysis and functioning as a de facto advocacy arm for OpenAI, according to sources familiar with the situation.‚Äù [...] ChatGPT‚Äôs ‚Äòadult mode‚Äô is expected to debut in Q1 2026\\nChatGPT‚Äôs ‚Äòadult mode‚Äô is expected to debut in Q1 2026\\nGPT-5.2 is OpenAI‚Äôs latest move in the agentic AI battle\\nGPT-5.2 is OpenAI‚Äôs latest move in the agentic AI battle\\nDisney accuses Google of ‚Äòmassive‚Äô copyright infringement following deal with OpenAI\\nDisney accuses Google of ‚Äòmassive‚Äô copyright infringement following deal with OpenAI\\nLawsuit claims ChatGPT put a ‚Äòtarget‚Äô on murdered woman\\nLawsuit claims ChatGPT put a ‚Äòtarget‚Äô on murdered woman\\nState AGs warn Google, Meta, and OpenAI that their chatbots could be breaking the law\\nState AGs warn Google, Meta, and OpenAI that their chatbots could be breaking the law\\nOpenAI‚Äôs billion-dollar Disney deal puts Mickey Mouse and Marvel in Sora [...] # OpenAI\\n\\nOpenAI kicked off an AI revolution with DALL-E and ChatGPT, making the organization the epicenter of the artificial intelligence boom. Led by CEO Sam Altman, OpenAI became a story unto itself when Altman was briefly fired and then brought back after pressure from staff and Microsoft, an investor and close partner.\\n\\nUnlike the consumer-facing ChatGPT Health announced Wednesday, the new OpenAI for Healthcare products launching today are designed do things like create reusable templates for discharge summaries and patient instructions, or analyze medical evidence to apply to specific patients.\\n\\nChatGPT for Healthcare is already being used by healthcare organizations like Boston Children‚Äôs Hospital, Memorial Sloan Kettering Cancer Center, and Stanford Medicine Children‚Äôs Health.\", \"score\": 0.9845754, \"raw_content\": null}, {\"url\": \"https://www.cnbc.com/2026/01/09/openai-and-softbank-group-announce-1-billion-investment-in-sb-energy-.html\", \"title\": \"OpenAI and SoftBank announce $1 billion investment in SB Energy ...\", \"content\": \"OpenAI has inked more than $1.4 trillion of infrastructure deals in recent months to try and build out the data centers it says are needed to meet growing demand. In November, OpenAI CEO Sam Altman said the company was on track to generate more than $20 billion in annualized revenue run rate in 2025, with plans to grow to hundreds of billions in sales by 2030.\\n\\nWATCH: Judge rules Elon Musk‚Äôs lawsuit over OpenAI for-profit conversion can head to trial\\n\\nFaber Report: Judge rules Elon Musk's lawsuit over OpenAI for-profit conversion can head to trial\\nCNBC logo\\n\\n#### News Tips\\n\\nGot a confidential news tip? We want to hear from you.\\n\\n#### CNBC Newsletters\\n\\nSign up for free newsletters and get more CNBC delivered to your inbox [...] CNBC\\nJoin IC\\nJoin Pro\\nJoin IC\\nJoin Pro\\n\\n# OpenAI and SoftBank announce $1 billion investment in SB Energy as part of massive AI buildout\\n\\nthumbnail\\n\\nOpenAI and SoftBank announced plans to invest $1 billion in SB Energy as part of a strategic partnership that will support OpenAI's artificial intelligence infrastructure buildout.\\n\\nThe partnership is part of the $500 billion Stargate commitment that OpenAI, SoftBank and Oracle announced last January at the White House, according to a Friday release. As part of the agreement, SB Energy will build and operate OpenAI's 1.2 gigawatt data center site in Milam County, Texas that was announced in September. [...] Two months after the Stargate project was announced, OpenAI said it closed a $40 billion financing round led by SoftBank, the largest private tech funding on record. The round included participation from core investor Microsoft, as well as Coatue, Altimeter and Thrive.\\n\\nSoftBank said in November that it's sold its entire stake in chipmaker Nvidia for $5.83 billion as it looks to capitalize on its \\\"all in\\\" bet on OpenAI.\\n\\nThe ChatGPT maker is burning through mounds of cash, and is still far from profitability, meaning it remains heavily reliant on outside capital.\", \"score\": 0.9829547, \"raw_content\": null}, {\"url\": \"https://developers.openai.com/blog/\", \"title\": \"OpenAI Developer Blog\", \"content\": \"OpenAI Developers\\n\\n## Search the blog\\n\\n### Categories\\n\\n### Topics\\n\\n### Getting Started\\n\\n### Using Codex\\n\\n### Configuration\\n\\n### Administration\\n\\n### Automation\\n\\n### Releases\\n\\n### Recent\\n\\n### Recent\\n\\n# OpenAI Developer Blog\\n\\nInsights for developers building with OpenAI\\n\\nOpenAI for Developers in 2025\\n\\nA year-end roundup of the biggest model, API, and platform shifts for building production-grade agents.\\n\\nUpdates for developers building with voice\\n\\nNew audio model snapshots and broader access to Custom Voices for production voice apps.\\n\\nWhat makes a great ChatGPT app\\n\\nHow to build capabilities that make conversations better.\\n\\nUsing Codex for education at Dagster Labs [...] Using Codex for education at Dagster Labs\\n\\nLearn how Dagster uses Codex in their open-source projects to accelerate documentation, translate content across mediums, and even measure how complete their docs are.\\n\\nHow Codex ran OpenAI DevDay 2025\\n\\nLearn how Codex helped us build experiences, demos, products, and more\\n\\nWhy we built the Responses API\\n\\nHow the Responses API unlocks persistent reasoning, hosted tools, and multimodal workflows for GPT-5.\\n\\nDeveloper notes on the Realtime API\\n\\nDetails worth noticing in recent realtime speech-to-speech updates\\n\\nHello, world!\\n\\nIntroducing our developer blog\", \"score\": 0.9615338, \"raw_content\": null}, {\"url\": \"https://openai.com/news/\", \"title\": \"OpenAI News\", \"content\": \"Stay up to speed on the rapid advancement of AI technology and the benefits it offers to humanity.\", \"score\": 0.8879841, \"raw_content\": null}, {\"url\": \"https://techcrunch.com/2026/01/10/openai-is-reportedly-asking-contractors-to-upload-real-work-from-past-jobs/\", \"title\": \"OpenAI is reportedly asking contractors to upload real work from ...\", \"content\": \"OpenAI and training data company Handshake AI are asking third-party contractors to upload real work that they did in past and current jobs, according to a report in Wired.\\n\\nThis appears to be part of a broader strategy across AI companies that are hiring contractors to generate high-quality training data in the hopes that this will eventually allow their models to automate more white-collar work.\\n\\nIn OpenAI‚Äôs case, a company presentation reportedly asks contractors to describe tasks they‚Äôve performed at other jobs and upload examples of ‚Äúreal, on-the-job work‚Äù that they‚Äôve ‚Äúactually done.‚Äù These examples can include ‚Äúa concrete output (not a summary of the file, but the actual file), e.g., Word doc, PDF, Powerpoint, Excel, image, repo.‚Äù [...] ### Topics\\n\\nLatest\\n\\nAI\\n\\nAmazon\\n\\nApps\\n\\nBiotech & Health\\n\\nClimate\\n\\nCloud Computing\\n\\nCommerce\\n\\nCrypto\\n\\nEnterprise\\n\\nEVs\\n\\nFintech\\n\\nFundraising\\n\\nGadgets\\n\\nGaming\\n\\nGoogle\\n\\nGovernment & Policy\\n\\nHardware\\n\\nInstagram\\n\\nLayoffs\\n\\nMedia & Entertainment\\n\\nMeta\\n\\nMicrosoft\\n\\nPrivacy\\n\\nRobotics\\n\\nSecurity\\n\\nSocial\\n\\nSpace\\n\\nStartups\\n\\nTikTok\\n\\nTransportation\\n\\nVenture\\n\\n### More from TechCrunch\\n\\nStaff\\n\\nEvents\\n\\nStartup Battlefield\\n\\nStrictlyVC\\n\\nNewsletters\\n\\nPodcasts\\n\\nVideos\\n\\nPartner Content\\n\\nTechCrunch Brand Studio\\n\\nCrunchboard\\n\\nContact Us\\n\\nPosted:\\n\\nOpenAI ChatGPT website displayed on a laptop screen is seen in this illustration photo.\\nAnthony Ha\\n\\n# OpenAI is reportedly asking contractors to upload real work from past jobs [...] The company reportedly instructs contractors to delete proprietary and personally identifiable information before uploading, and it points them to a ChatGPT ‚ÄúSuperstar Scrubbing‚Äù tool to do so.\\n\\nNonetheless, intellectual property lawyer Evan Brown told Wired that any AI lab taking this approach is ‚Äúputting itself at great risk‚Äù with an approach that requires ‚Äúa lot of trust in its contractors to decide what is and isn‚Äôt confidential.‚Äù\\n\\nAn OpenAI spokesperson declined to comment.\\n\\nTopics\\n\\nEvent Logo\\n\\nPlan ahead for the 2026 StrictlyVC events. Hear straight-from-the-source candid insights in on-stage fireside sessions and meet the builders and backers shaping the industry. Join the waitlist to get first access to the lowest-priced tickets and important updates.\\n\\n### Newsletters\", \"score\": 0.7122322, \"raw_content\": null}], \"response_time\": 2.99, \"request_id\": \"d2a2c2a1-ccfb-434e-bbb9-bf15be8f6dd4\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "It appears that OpenAI has been making significant advancements in the field of artificial intelligence, particularly with the development of its ChatGPT model. The company has also been making efforts to expand its infrastructure and capabilities, including the announcement of a $1 billion investment in SB Energy.\n",
      "\n",
      "However, there are also concerns about the potential risks and downsides of AI, including the issue of intellectual property and the potential for AI to automate white-collar work.\n",
      "\n",
      "Overall, it seems that OpenAI is continuing to push the boundaries of what is possible with AI, but also faces challenges and controversies along the way.\n",
      "\n",
      "To get a better understanding of the current state of OpenAI and its developments, I would like to call the Arxiv function to search for recent papers on the topic.\n",
      "\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: arxiv\n",
      "    Args: {'query': 'OpenAI recent papers'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "Published: 2019-01-18\n",
      "Title: Learning Dexterous In-Hand Manipulation\n",
      "Authors: OpenAI, Marcin Andrychowicz, Bowen Baker, Maciek Chociej, Rafal Jozefowicz, Bob McGrew, Jakub Pachocki, Arthur Petron, Matthias Plappert, Glenn Powell, Alex Ray, Jonas Schneider, Szymon Sidor, Josh Tobin, Peter Welinder, Lilian Weng, Wojciech Zaremba\n",
      "Summary: We use reinforcement learning (RL) to learn dexterous in-hand manipulation policies which can perform vision-based object reorientation on a physical Shadow Dexterous Hand. The training is performed in a simulated environment in which we randomize many of the physical properties of the system like friction coefficients and an object's appearance. Our policies transfer to the physical robot despite being trained entirely in simulation. Our method does not rely on any human demonstrations, but many behaviors found in human manipulation emerge naturally, including finger gaiting, multi-finger coordination, and the controlled use of gravity. Our results were obtained using the same distributed RL system that was used to train OpenAI Five. We also include a video of our results: https://youtu.be/jwSbzNHGflM\n",
      "\n",
      "Published: 2024-12-21\n",
      "Title: OpenAI o1 System Card\n",
      "Authors: OpenAI, :, Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, Alex Iftimie, Alex Karpenko, Alex Tachard Passos, Alexander Neitz, Alexander Prokofiev, Alexander Wei, Allison Tam, Ally Bennett, Ananya Kumar, Andre Saraiva, Andrea Vallone, Andrew Duberstein, Andrew Kondrich, Andrey Mishchenko, Andy Applebaum, Angela Jiang, Ashvin Nair, Barret Zoph, Behrooz Ghorbani, Ben Rossen, Benjamin Sokolowsky, Boaz Barak, Bob McGrew, Borys Minaiev, Botao Hao, Bowen Baker, Brandon Houghton, Brandon McKinzie, Brydon Eastman, Camillo Lugaresi, Cary Bassin, Cary Hudson, Chak Ming Li, Charles de Bourcy, Chelsea Voss, Chen Shen, Chong Zhang, Chris Koch, Chris Orsinger, Christopher Hesse, Claudia Fischer, Clive Chan, Dan Roberts, Daniel Kappler, Daniel Levy, Daniel Selsam, David Dohan, David Farhi, David Mely, David Robinson, Dimitris Tsipras, Doug Li, Dragos Oprica, Eben Freeman, Eddie Zhang, Edmund Wong, Elizabeth Proehl, Enoch Cheung, Eric Mitchell, Eric Wallace, Erik Ritter, Evan Mays, Fan Wang, Felipe Petroski Such, Filippo Raso, Florencia Leoni, Foivos Tsimpourlas, Francis Song, Fred von Lohmann, Freddie Sulit, Geoff Salmon, Giambattista Parascandolo, Gildas Chabot, Grace Zhao, Greg Brockman, Guillaume Leclerc, Hadi Salman, Haiming Bao, Hao Sheng, Hart Andrin, Hessam Bagherinezhad, Hongyu Ren, Hunter Lightman, Hyung Won Chung, Ian Kivlichan, Ian O'Connell, Ian Osband, Ignasi Clavera Gilaberte, Ilge Akkaya, Ilya Kostrikov, Ilya Sutskever, Irina Kofman, Jakub Pachocki, James Lennon, Jason Wei, Jean Harb, Jerry Twore, Jiacheng Feng, Jiahui Yu, Jiayi Weng, Jie Tang, Jieqi Yu, Joaquin Qui√±onero Candela, Joe Palermo, Joel Parish, Johannes Heidecke, John Hallman, John Rizzo, Jonathan Gordon, Jonathan Uesato, Jonathan Ward, Joost Huizinga, Julie Wang, Kai Chen, Kai Xiao, Karan Singhal, Karina Nguyen, Karl Cobbe, Katy Shi, Kayla Wood, Kendra Rimbach, Keren Gu-Lemberg, Kevin Liu, Kevin Lu, Kevin Stone, Kevin Yu, Lama Ahmad, Lauren Yang, Leo Liu, Leon Maksin, Leyton Ho, Liam Fedus, Lilian Weng, Linden Li, Lindsay McCallum, Lindsey Held, Lorenz Kuhn, Lukas Kondraciuk, Lukasz Kaiser, Luke Metz, Madelaine Boyd, Maja Trebacz, Manas Joglekar, Mark Chen, Marko Tintor, Mason Meyer, Matt Jones, Matt Kaufer, Max Schwarzer, Meghan Shah, Mehmet Yatbaz, Melody Y. Guan, Mengyuan Xu, Mengyuan Yan, Mia Glaese, Mianna Chen, Michael Lampe, Michael Malek, Michele Wang, Michelle Fradin, Mike McClay, Mikhail Pavlov, Miles Wang, Mingxuan Wang, Mira Murati, Mo Bavarian, Mostafa Rohaninejad, Nat McAleese, Neil Chowdhury, Neil Chowdhury, Nick Ryder, Nikolas Tezak, Noam Brown, Ofir Nachum, Oleg Boiko, Oleg Murk, Olivia Watkins, Patrick Chao, Paul Ashbourne, Pavel Izmailov, Peter Zhokhov, Rachel Dias, Rahul Arora, Randall Lin, Rapha Gontijo Lopes, Raz Gaon, Reah Miyara, Reimar Leike, Renny Hwang, Rhythm Garg, Robin Brown, Roshan James, Rui Shu, Ryan Cheu, Ryan Greene, Saachi Jain, Sam Altman, Sam Toizer, Sam Toyer, Samuel Miserendino, Sandhini Agarwal, Santiago Hernandez, Sasha Baker, Scott McKinney, Scottie Yan, Shengjia Zhao, Shengli Hu, Shibani Santurkar, Shraman Ray Chaudhuri, Shuyuan Zhang, Siyuan Fu, Spencer Papay, Steph Lin, Suchir Balaji, Suvansh Sanjeev, Szymon Sidor, Tal Broda, Aidan Clark, Tao Wang, Taylor Gordon, Ted Sanders, Tejal Patwardhan, Thibault Sottiaux, Thomas Degry, Thomas Dimson, Tianhao Zheng, Timur Garipov, Tom Stasi, Trapit Bansal, Trevor Creech, Troy Peterson, Tyna Eloundou, Valerie Qi, Vineet Kosaraju, Vinnie Monaco, Vitchyr Pong, Vlad Fomenko, Weiyi Zheng, Wenda Zhou, Wes McCabe, Wojciech Zaremba, Yann Dubois, Yinghai Lu, Yining Chen, Young Cha, Yu Bai, Yuchen He, Yuchen Zhang, Yunyun Wang, Zheng Shao, Zhuohan Li\n",
      "Summary: The o1 model series is trained wi\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "Unfortunately, the provided Arxiv search did not return any relevant papers. The top result was an older paper from 2019 about learning dexterous in-hand manipulation, and the second result was an OpenAI system card from 2024, which is not a research paper. If you would like to search for more recent papers on OpenAI, I suggest trying a different search query or using a different search tool.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "I'm here to assist you with your research. What topic or question would you like to explore today?\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'end_date': None, 'exclude_domains': None, 'include_domains': None, 'include_images': True, 'query': 'AI news today', 'search_depth': 'basic', 'start_date': None, 'time_range': 'day', 'topic': 'news'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"AI news today\", \"follow_up_questions\": null, \"answer\": null, \"images\": [\"https://i.ytimg.com/vi/h5u4bgErk0g/maxresdefault.jpg\", \"https://australianfintech.com.au/wp-content/uploads/sites/7/2023/11/IN-AI-TODAY-600x600-1.png\", \"https://i1.sndcdn.com/avatars-zck46tNnBZij8Qcz-Dc0mYA-original.jpg\", \"https://digitrendz.blog/wp-content/uploads/2023/12/AI_news_update.png\", \"https://hbtech.co.in/wp-content/uploads/2024/12/Breaking-Down-Todays-AI-News-3-1.png\"], \"results\": [{\"url\": \"https://www.reuters.com/technology/artificial-intelligence/\", \"title\": \"AI News | Latest Headlines and Developments\", \"content\": \"Explore the latest artificial intelligence news with Reuters - from AI breakthroughs and technology trends to regulation, ethics, business and global\", \"score\": 0.9979493, \"raw_content\": null}, {\"url\": \"https://www.shrm.org/topics-tools/flagships/ai-hi/quick-hits-jan-12\", \"title\": \"Quick Hits in AI News: The Importance of Human Skills\", \"content\": \"The report finds that AI adoption continues to rise but remains uneven, with strong gains for individuals and persistent friction at team and organizational\", \"score\": 0.96691406, \"raw_content\": null}, {\"url\": \"https://finance.yahoo.com/news/artificial-intelligence-ai-stock-finally-155000457.html\", \"title\": \"Is This Artificial Intelligence (AI) Stock Finally Entering Its ...\", \"content\": \"AI investment is already juicing revenue, and the stock price has finally begun to rise. 10 stocks we like better than Texas Instruments ‚Ä∫. I've got a great\", \"score\": 0.8267118, \"raw_content\": null}, {\"url\": \"https://www.stocktitan.net/news/EVTV/azio-receives-100-million-worth-of-government-purchase-orders-8269s7z35kl6.html\", \"title\": \"AZIO AI, EVTV: $107M gov order, $200M AI pipeline builds\", \"content\": \"AZIO AI secures a 256-unit Nvidia GPU order worth about $107M, eyes up to $200M more in regional deals and advances a $3-per-share merger plan with EVTV.\", \"score\": 0.79565805, \"raw_content\": null}, {\"url\": \"https://news.samsung.com/us/ai-is-already-revolutionizing-mobile-phone-experience-most-users-dont-even-realize/\", \"title\": \"AI is Already Revolutionizing the Mobile Phone Experience\", \"content\": \"AI is already embedded in everyday mobile phone experiences, with 90% of Americans using AI features ‚Äî often without realizing it.\", \"score\": 0.7690802, \"raw_content\": null}], \"response_time\": 1.26, \"request_id\": \"6284e7f1-2512-404c-9919-8fc95574482e\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'exclude_domains': None, 'include_domains': None, 'include_images': False, 'query': 'AI news today breakthroughs', 'search_depth': 'basic', 'start_date': None, 'time_range': 'day', 'topic': 'news'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"AI news today breakthroughs\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.reuters.com/technology/artificial-intelligence/\", \"title\": \"AI News | Latest Headlines and Developments\", \"content\": \"Explore the latest artificial intelligence news with Reuters - from AI breakthroughs and technology trends to regulation, ethics, business and global impact.\", \"score\": 0.99771273, \"raw_content\": null}, {\"url\": \"https://www.thenews.com.pk/latest/1388150-ai-breakthrough-tool-to-shrink-years-of-drug-discovery-into-days\", \"title\": \"AI breakthrough tool to shrink years of drug discovery into ...\", \"content\": \"Scientists at Tsinghua University have developed a powerful system called DrugCLIP, which can screen drug molecules against human proteins at staggering speed\", \"score\": 0.9941347, \"raw_content\": null}, {\"url\": \"https://finance.yahoo.com/news/ai-chips-today-kyro-revolutionizes-113713429.html\", \"title\": \"Kyro Revolutionizes Robotics With Physical AI Breakthrough\", \"content\": \"At CES 2026, AMC Robotics Corporation unveiled Kyro‚Ñ¢, a quadruped robotic platform designed to harness advanced artificial intelligence capabilities,\", \"score\": 0.99021614, \"raw_content\": null}, {\"url\": \"https://www.sciencedaily.com/news/computers_math/artificial_intelligence/\", \"title\": \"Artificial Intelligence News -- ScienceDaily\", \"content\": \"Brain-Inspired AI Breakthrough: Making Computers See More Like Humans ¬∑ AI Tool Grounded in Evidence-Based Medicine Outperformed Other AI Tools -- And Most\", \"score\": 0.9885804, \"raw_content\": null}, {\"url\": \"https://www.nature.com/news\", \"title\": \"Latest science news, discoveries and analysis\", \"content\": \"Breaking the plasma density limit brings researchers a step closer to viable fusion reactors. news | 09 Jan 2026. AI models were given four weeks of therapy:\", \"score\": 0.81757444, \"raw_content\": null}], \"response_time\": 1.02, \"request_id\": \"b2485259-83fa-4484-9e82-f3694bfef276\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: arxiv\n",
      "    Args: {'query': 'AI breakthroughs 2026'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "Published: 2025-01-06\n",
      "Title: Foundations of GenIR\n",
      "Authors: Qingyao Ai, Jingtao Zhan, Yiqun Liu\n",
      "Summary: The chapter discusses the foundational impact of modern generative AI models on information access (IA) systems. In contrast to traditional AI, the large-scale training and superior data modeling of generative AI models enable them to produce high-quality, human-like responses, which brings brand new opportunities for the development of IA paradigms. In this chapter, we identify and introduce two of them in details, i.e., information generation and information synthesis. Information generation allows AI to create tailored content addressing user needs directly, enhancing user experience with immediate, relevant outputs. Information synthesis leverages the ability of generative AI to integrate and reorganize existing information, providing grounded responses and mitigating issues like model hallucination, which is particularly valuable in scenarios requiring precision and external knowledge. This chapter delves into the foundational aspects of generative models, including architecture, scaling, and training, and discusses their applications in multi-modal scenarios. Additionally, it examines the retrieval-augmented generation paradigm and other methods for corpus modeling and understanding, demonstrating how generative AI can enhance information access systems. It also summarizes potential challenges and fruitful directions for future studies.\n",
      "\n",
      "Published: 2026-01-09\n",
      "Title: The ICASSP 2026 HumDial Challenge: Benchmarking Human-like Spoken Dialogue Systems in the LLM Era\n",
      "Authors: Zhixian Zhao, Shuiyuan Wang, Guojian Li, Hongfei Xue, Chengyou Wang, Shuai Wang, Longshuai Xiao, Zihan Zhang, Hui Bu, Xin Xu, Xinsheng Wang, Hexin Liu, Eng Siong Chng, Hung-yi Lee, Haizhou Li, Lei Xie\n",
      "Summary: Driven by the rapid advancement of Large Language Models (LLMs), particularly Audio-LLMs and Omni-models, spoken dialogue systems have evolved significantly, progressively narrowing the gap between human-machine and human-human interactions. Achieving truly ``human-like'' communication necessitates a dual capability: emotional intelligence to perceive and resonate with users' emotional states, and robust interaction mechanisms to navigate the dynamic, natural flow of conversation, such as real-time turn-taking. Therefore, we launched the first Human-like Spoken Dialogue Systems Challenge (HumDial) at ICASSP 2026 to benchmark these dual capabilities. Anchored by a sizable dataset derived from authentic human conversations, this initiative establishes a fair evaluation platform across two tracks: (1) Emotional Intelligence, targeting long-term emotion understanding and empathetic generation; and (2) Full-Duplex Interaction, systematically evaluating real-time decision-making under `` listening-while-speaking'' conditions. This paper summarizes the dataset, track configurations, and the final results.\n",
      "\n",
      "Published: 2025-08-31\n",
      "Title: Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations\n",
      "Authors: Lun Ai, Johannes Langer, Ute Schmid, Stephen Muggleton\n",
      "Summary: Ultra Strong Machine Learning (USML) refers to symbolic learning systems that not only improve their own performance but can also teach their acquired knowledge to quantifiably improve human performance. In this work, we present LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic method that combines symbolic program synthesis with large language models (LLMs) to automate the explanation of machine-learned logic programs in natural language. LENS addresses a key limitation of prior USML approaches by replacing hand-crafted explanation templates with scalable automated generation. Through systematic evaluation using multiple LLM judges and human validation, we demonstrate that LENS generates superior explanations compared to direct LLM prompting and hand-crafted templates. To investigate whether LENS can teach transferable active learning strategies, we carried out a human learning experiment across three related domains. Our results show no significant human performance improvements, suggesting that comprehensive LLM responses may overwhelm users for simpler problems rather than providing learning support. Our work provides a solid foundation for building effective USML systems to support human learning. The source code is available on: https://github.com/lun-ai/LENS.git.\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "The latest AI news today includes breakthroughs in AI-powered drug discovery, AI chips, and robotics. Researchers have developed a powerful system called DrugCLIP, which can screen drug molecules against human proteins at staggering speed. Additionally, Kyro, a quadruped robotic platform, has been unveiled, designed to harness advanced artificial intelligence capabilities. Furthermore, AI models are being used to improve information access systems, with the ability to generate tailored content addressing user needs directly and integrate and reorganize existing information to provide grounded responses.\n",
      "\n",
      "The ICASSP 2026 HumDial Challenge has been launched to benchmark human-like spoken dialogue systems in the LLM era, focusing on emotional intelligence and full-duplex interaction. The challenge aims to establish a fair evaluation platform across two tracks: Emotional Intelligence and Full-Duplex Interaction.\n",
      "\n",
      "Ultra Strong Machine Learning (USML) refers to symbolic learning systems that not only improve their own performance but can also teach their acquired knowledge to quantifiably improve human performance. LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic method, has been developed to automate the explanation of machine-learned logic programs in natural language. LENS addresses a key limitation of prior USML approaches by replacing hand-crafted explanation templates with scalable automated generation.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'end_date': None, 'exclude_domains': [], 'include_domains': [], 'include_images': False, 'query': 'current date', 'search_depth': 'basic', 'start_date': None, 'time_range': None, 'topic': 'general'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"current date\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"title\": \"Today's Date | Current date now - RapidTables.com\", \"content\": \"This page includes the following information: Today's date: day of week, month, day, year. Current time: hours, minutes, seconds.\", \"score\": 0.8740772, \"raw_content\": null}, {\"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"title\": \"What Is Today's Date? - Inch Calculator\", \"content\": \"Today, January 11th , is day 11 of 365 total days in 2026. What is Today's Date in Numbers? Today's date in numbers is: MM-DD-YYYY: 01-11-2026; DD-MM-YYYY:\", \"score\": 0.5832034, \"raw_content\": null}, {\"url\": \"https://www.datetoday.net/\", \"title\": \"What is the date today? Today's Date\", \"content\": \"Q: What is today's date? A: Today is Monday, January 12, 2026. Q: What day of the week is it? A:\", \"score\": 0.43398148, \"raw_content\": null}, {\"url\": \"https://www.calendardate.com/todays.htm\", \"title\": \"Today's Date - CalendarDate.com\", \"content\": \"Details about today's date with count of days, weeks, and months, Sun and Moon cycles, Zodiac signs and holidays.\", \"score\": 0.18359362, \"raw_content\": null}, {\"url\": \"https://www.timeanddate.com/\", \"title\": \"Time and Date\", \"content\": \"Welcome to the world's top site for time, time zones, and astronomy. Organize your life with free online info and tools you can rely on. No sign-up needed.\", \"score\": 0.105210535, \"raw_content\": null}], \"response_time\": 0.66, \"request_id\": \"c7c37517-1637-4ad8-abda-2bda3ff21ded\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "Today's date is January 12th, 2026.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n",
      "\n",
      "================ NEW QUERY ================\n",
      "\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "\n",
      "üõ† TOOL CALLS:\n",
      "  ‚Üí Tool: arxiv\n",
      "    Args: {'query': 'Transformer paper original introduction influence LLMs'}\n",
      "  ‚Üí Tool: tavily_search\n",
      "    Args: {'end_date': '2022-01-01', 'query': 'Transformer paper influence modern LLMs', 'search_depth': 'advanced', 'start_date': '2020-01-01', 'topic': 'general'}\n",
      "\n",
      "üîπ NODE: tools\n",
      "üîß TOOL OUTPUT:\n",
      "{\"query\": \"Transformer paper influence modern LLMs\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/Attention_Is_All_You_Need\", \"title\": \"Attention Is All You Need - Wikipedia\", \"content\": \"## Methods discussed and introduced\\n\\n[edit]\\n\\nThe paper is most well known for the introduction of the Transformer architecture, which forms the underlying architecture for most forms of modern large language models (LLMs). A key reason for why the architecture is preferred by most modern LLMs is the parallelizability of the architecture over its predecessors. This ensures that the operations necessary for training can be accelerated on a GPU allowing both faster training times and models of bigger sizes to be trained.\\n\\nThe following mechanisms were introduced by the paper as part of the development of the transformer architecture.\\n\\nScaled dot-product attention & self-attention [...] \\\"Attention Is All You Need\\\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer \\\"Transformer (machine learning model)\\\"), based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wide variety of AI, such as large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as [...] The paper's title is a reference to the song \\\"All You Need Is Love\\\" by the Beatles. The name \\\"Transformer\\\" was picked because Jakob Uszkoreit, one of the paper's authors, liked the sound of that word. An early design document was titled \\\"Transformers: Iterative Self-Attention and Processing for Various Tasks\\\", and included an illustration of six characters from the Transformers franchise. The team was named Team Transformer.\\n\\n## Methods discussed and introduced\\n\\n[edit]\", \"score\": 0.99883956, \"raw_content\": null}, {\"url\": \"https://arxiv.org/abs/2508.09834\", \"title\": \"A Survey on Efficient Architectures for Large Language Models - arXiv\", \"content\": \"> Abstract:Large Language Models (LLMs) have delivered impressive results in language understanding, generation, reasoning, and pushes the ability boundary of multimodal models. Transformer models, as the foundation of modern LLMs, offer a strong baseline with excellent scaling properties. However, the traditional transformer architecture requires substantial computations and poses significant obstacles for large-scale training and practical deployment. In this survey, we offer a systematic examination of innovative LLM architectures that address the inherent limitations of transformers and boost the efficiency. Starting from language modeling, this survey covers the background and technical details of linear and sparse sequence modeling methods, efficient full attention variants, sparse\", \"score\": 0.9982039, \"raw_content\": null}, {\"url\": \"https://www.womentech.net/blog/developing-ai-powered-solutions-deep-dive-large-language-models-1\", \"title\": \"Developing AI-Powered Solutions: A Deep Dive into Large ...\", \"content\": \"Transformers are composed of two main components: the encoder and the decoder. The encoder's role is to process the input text, analyzing and encoding it into a format that the model can understand. The decoder then takes this encoded information and generates the output text, ensuring that it is coherent and contextually relevant. The use of Transformers has been instrumental in advancing LLMs' capabilities, enabling them to perform complex language tasks such as translation, summarization, and creative writing with unprecedented accuracy and fluency.\\n\\n## How Do Large Language Models (LLMs) Work? [...] The evolution of Large Language Models has been a journey marked by significant milestones, beginning with early neural network models. A pivotal moment in this journey was the introduction of the Transformer architecture, proposed by Vaswani et al. in their groundbreaking 2017 paper, \\\"Attention Is All You Need.\\\" The Transformer architecture revolutionized the field by improving the efficiency and performance of language models, allowing them to process and generate text with greater accuracy and coherence. [...] The release of GPT-3 in June 2020 took LLMs to new heights, featuring a staggering 175 billion parameters. GPT-3's remarkable capabilities enabled a wide array of applications, ranging from creative writing and content generation to programming assistance and beyond. The model's versatility demonstrated the vast potential of LLMs to influence various domains.\", \"score\": 0.99793327, \"raw_content\": null}, {\"url\": \"https://magazine.sebastianraschka.com/p/understanding-large-language-models\", \"title\": \"Understanding Large Language Models - Ahead of AI\", \"content\": \"For instance, in 1991, which is about two-and-a-half decades before the original transformer paper above (\\\"Attention Is All You Need\\\"), Juergen Schmidhuber proposed an alternative to recurrent neural networks called Fast Weight Programmers (FWP). The FWP approach involves a feedforward neural network that slowly learns by gradient descent to program the changes of the fast weights of another neural network.\\n\\nThe analogy to modern transformers is explained in this blog post as follows: [...] The original GPT paper introduced the popular decoder-style architecture and pretraining via next-word prediction. Where BERT can be considered a bidirectional transformer due to its masked language model pretraining objective, GPT is a unidirectional, autoregressive model. While GPT embeddings can also be used for classification, the GPT approach is at the core of today‚Äôs most influential LLMs, such as chatGPT. [...] The paper above introduces the original transformer architecture consisting of an encoder- and decoder part that will become relevant as separate modules later. Moreover, this paper introduces concepts such as the scaled dot product attention mechanism, multi-head attention blocks, and positional input encoding that remain the foundation of modern transformers.\\n\\n(3) On Layer Normalization in the Transformer Architecture (2020) by Xiong, Yang, He, K Zheng, S Zheng, Xing, Zhang, Lan, Wang, and Liu, \\n\\nWhile the original transformer figure above (from Attention Is All You Need, ) is a helpful summary of the original encoder-decoder architecture, the location of the LayerNorm in this figure remains a hotly debated subject.\", \"score\": 0.9975274, \"raw_content\": null}, {\"url\": \"https://www.ibm.com/think/topics/transformer-model\", \"title\": \"What is a Transformer Model? - IBM\", \"content\": \"Encoder-decoder masked language models (MLMs), such as BERT and its many derivatives, represent the other main evolutionary branch of transformer-based LLMs. In training, an MLM is provided a text sample with some tokens masked‚Äîhidden‚Äîand tasked with completing the missing information.  \\n   \\n While this training methodology is less effective for text generation, it helps MLMs excel at tasks requiring robust contextual information, such as translation, text classification and learning embeddings.\\n\\n## Transformer models in other fields [...] BERT (or Bidirectional Encoder Representations from Transformers), an encoder-only model introduced by Google in 2019, was a major landmark in the establishment of transformers and remains the basis of most modern word embedding applications, from modern vector databases to Google search.\\n\\nAutoregressive decoder-only LLMs, such as the GPT-3 (short for Generative Pre-trained Transformer) model that powered the launch of OpenAI‚Äôs ChatGPT, catalyzed the modern era of generative AI (gen AI). [...] In autoregressive LLMs, the final layer uses a softmax function to determine the probability that the next word will match each token in its vocabulary ‚Äúdatabase.‚Äù Depending on the specific sampling hyperparameters, the model uses those probabilities to determine the next token of the output sequence.\\n\\n## Transformer models in natural language processing (NLP)\\n\\nTransformer models are most commonly associated with NLP, having originally been developed for machine translation use cases. Most notably, the transformer architecture gave rise to the large language models (LLMs) that catalyzed the advent of generative AI.\", \"score\": 0.9962346, \"raw_content\": null}], \"response_time\": 1.71, \"request_id\": \"27ba855e-4f90-4f7c-8958-cac15ef2d68a\"}\n",
      "\n",
      "üîπ NODE: tool_calling_llm\n",
      "ü§ñ LLM OUTPUT:\n",
      "The original paper that introduced transformers is \"Attention Is All You Need\" by Vaswani et al. in 2017. The transformers architecture revolutionized the field of natural language processing (NLP) by improving the efficiency and performance of language models, allowing them to process and generate text with greater accuracy and coherence.\n",
      "\n",
      "The transformers architecture has had a significant influence on modern large language models (LLMs), enabling them to perform complex language tasks such as translation, summarization, and creative writing with unprecedented accuracy and fluency. The use of transformers has been instrumental in advancing LLMs' capabilities, and they have become the foundation of most modern LLMs.\n",
      "\n",
      "The transformers architecture has also been extended and modified in various ways, including the introduction of encoder-decoder models, masked language models, and autoregressive decoder-only models. These extensions have enabled LLMs to excel at a wide range of tasks, from text classification and learning embeddings to generative AI.\n",
      "\n",
      "In summary, the transformers architecture has had a profound impact on the development of modern LLMs, enabling them to perform complex language tasks with unprecedented accuracy and fluency.\n",
      "\n",
      "=============== FINAL ANSWER ===============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab2ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
